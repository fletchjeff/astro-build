"""
mlflow_integration_test
DAG auto-generated by Astro Cloud IDE.
"""

from airflow.decorators import dag
from airflow.models import Variable
from astro import sql as aql
import pandas as pd
import pendulum

import mlflow
import xgboost as xgb
import os
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


@aql.dataframe(task_id="cell_1")
def cell_1_func():
    X, y = load_diabetes(return_X_y=True, as_frame=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    os.environ['AWS_ACCESS_KEY_ID'] = Variable.get('AWS_ACCESS_KEY_ID')
    os.environ['AWS_SECRET_ACCESS_KEY'] = Variable.get('AWS_SECRET_ACCESS_KEY')
    # enable auto logging
    # this includes xgboost.sklearn estimators
    mlflow.xgboost.autolog()
    mlflow.set_tracking_uri("http://astroaws.fletcher.za.net:5000")
    mlflow.set_experiment("train_model_cide")
    
    regressor = xgb.XGBRegressor(n_estimators=20, reg_lambda=1, gamma=0, max_depth=3)
    regressor.fit(X_train, y_train, eval_set=[(X_test, y_test)])
    y_pred = regressor.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    run_id = mlflow.last_active_run().info.run_id
    return "Logged data and model in run {}".format(run_id)

@dag(
    schedule_interval="0 0 * * *",
    start_date=pendulum.from_format("2022-12-29", "YYYY-MM-DD").in_tz("Europe/Amsterdam"),
)
def mlflow_integration_test():
    cell_1 = cell_1_func()

dag_obj = mlflow_integration_test()
